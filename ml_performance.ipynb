{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ml_fileObject:\n",
    "\n",
    "    def __init__(self, root, index):\n",
    "        self.root = root\n",
    "        self.index = index\n",
    "        self.path = os.path.join(root, str(index))\n",
    "        for files in os.listdir(self.path):\n",
    "            if files.startswith('IMU'):\n",
    "                self.imu_path = os.path.join(self.path, files)\n",
    "            elif files.startswith('Mag'):\n",
    "                self.mag_path = os.path.join(self.path, files)\n",
    "            elif files.startswith('ultra'):\n",
    "                self.ultra_path = os.path.join(self.path, files)\n",
    "        self.height_dict = {\n",
    "            '1': 0.736,\n",
    "            '2': 0.782,\n",
    "            '3': 0.827,\n",
    "            '4': 0.877,\n",
    "            '5': 0.936,\n",
    "            '6': 0.981,\n",
    "            '7': 1.043,\n",
    "            '8': 1.102\n",
    "        }\n",
    "\n",
    "    def get_ultra(self):\n",
    "        Dataframe = pd.read_csv(self.ultra_path, sep=\" \",\n",
    "                                names=[\"ID\", \"P_x\", \"P_y\", \"P_z\", \"unknow\", \"unknow_1\", \"Time_Stamp\"])\n",
    "        Dataframe = Dataframe.drop([\"ID\", \"unknow\", \"unknow_1\"], axis=1)\n",
    "        rows, columns = Dataframe.shape\n",
    "        serial_num = np.arange(0, rows, 1).tolist()\n",
    "        serial_num_inte = np.arange(0, rows, 0.1).tolist()\n",
    "        Px_inte = np.interp(serial_num_inte, serial_num, Dataframe[\"P_x\"])\n",
    "        Py_inte = np.interp(serial_num_inte, serial_num, Dataframe[\"P_y\"])\n",
    "        Pz_inte = np.interp(serial_num_inte, serial_num, Dataframe[\"P_z\"])\n",
    "        Pt_inte = np.interp(serial_num_inte, serial_num, Dataframe[\"Time_Stamp\"])\n",
    "        Dataframe_inte = pd.DataFrame(columns=[\"Serial_Num\", 'P_X', 'P_Y', 'P_Z', \"Time_Stamp\"])\n",
    "        Dataframe_inte[\"Serial_Num\"] = np.arange(0, len(serial_num_inte), 1).tolist()\n",
    "        Dataframe_inte[\"P_X\"] = Px_inte\n",
    "        Dataframe_inte[\"P_Y\"] = Py_inte\n",
    "        Dataframe_inte['P_Z'] = self.height_dict[str(self.index)]\n",
    "        # Dataframe_inte[\"P_Z\"] = Pz_inte\n",
    "        Dataframe_inte[\"Time_Stamp\"] = Pt_inte\n",
    "        return Dataframe_inte\n",
    "\n",
    "    def get_mag(self):\n",
    "        df_tem = pd.read_csv(self.mag_path, sep=\" \", names=[\"Serial_Num\", \"R_x\", \"R_y\", \"R_z\", \"Time_Stamp\"],\n",
    "                             index_col=\"Serial_Num\")\n",
    "        df_tem[\"Magnitude\"] = np.sqrt(\n",
    "            np.power(df_tem[\"R_x\"], 2) + np.power(df_tem[\"R_y\"], 2) + np.power(df_tem[\"R_z\"], 2))\n",
    "        return df_tem\n",
    "\n",
    "    def get_imu(self):\n",
    "        df_tem = pd.read_csv(self.imu_path, sep=\" \",\n",
    "                             names=['a_x', 'a_y', 'a_z', 'G_x', 'G_y', 'G_z', 'M_x', 'M_y', 'M_z', 'alpha', 'beta',\n",
    "                                    'gama', 'mill', 'Time_Stamp', 'index'],\n",
    "                             index_col=\"index\")\n",
    "        return df_tem\n",
    "\n",
    "    def get_IMU_info(self, time_mag, df_imu):\n",
    "        time_imu = df_imu['Time_Stamp'].to_numpy()\n",
    "        sub_array = abs(time_imu - time_mag)\n",
    "        index = np.argmin(sub_array)\n",
    "        alpha, beta, gama = df_imu.iloc[index, 9], df_imu.iloc[index, 10], df_imu.iloc[index, 11]\n",
    "        a_x, a_y, a_z = df_imu.iloc[index, 0], df_imu.iloc[index, 1], df_imu.iloc[index, 2]\n",
    "        return a_x, a_y, a_z, alpha, beta, gama\n",
    "\n",
    "    def get_position(self, time_mag, df_ultra):\n",
    "        time_ultra = df_ultra['Time_Stamp'].to_numpy()\n",
    "        sub_array = abs(time_ultra - time_mag)\n",
    "        index = np.argmin(sub_array)\n",
    "        p_x, p_y, p_z = df_ultra.iloc[index, 1], df_ultra.iloc[index, 2], df_ultra.iloc[index, 3]\n",
    "        # print(p_x,p_y,p_z)\n",
    "        return p_x, p_y, p_z\n",
    "\n",
    "    def merge_all(self):\n",
    "        df_mag = self.get_mag()\n",
    "        df_ultra = self.get_ultra()\n",
    "        df_imu = self.get_imu()\n",
    "        position = []\n",
    "        imu_data = []\n",
    "        for i in range(df_mag.shape[0]):\n",
    "            position.append(self.get_position(df_mag.iloc[i, 3], df_ultra))\n",
    "            imu_data.append(self.get_IMU_info(df_mag.iloc[i, 3], df_imu))\n",
    "        position_array = np.array(position)\n",
    "        imu_data_array = np.array(imu_data)\n",
    "        df_mag['p_x'] = position_array[:, 0]\n",
    "        df_mag['p_y'] = position_array[:, 1]\n",
    "        df_mag['p_z'] = position_array[:, 2]\n",
    "        df_mag['d_t1'] = np.sqrt(\n",
    "            np.power(position_array[:, 0] - 1.90, 2) + np.power(position_array[:, 1] - 0.17, 2) + np.power(\n",
    "                position_array[:, 2] - 1.24, 2))\n",
    "        df_mag['d_t2'] = np.sqrt(\n",
    "            np.power(position_array[:, 0] - 5.00, 2) + np.power(position_array[:, 1] - 0.33, 2) + np.power(\n",
    "                position_array[:, 2] - 1.24, 2))\n",
    "        df_mag['d_t3'] = np.sqrt(\n",
    "            np.power(position_array[:, 0] - 3.23, 2) + np.power(position_array[:, 1] + 2.94, 2) + np.power(\n",
    "                position_array[:, 2] - 1.24, 2))\n",
    "        df_mag['a_x'] = imu_data_array[:, 0]\n",
    "        df_mag['a_y'] = imu_data_array[:, 1]\n",
    "        df_mag['a_z'] = imu_data_array[:, 2]\n",
    "        df_mag['alpha'] = imu_data_array[:, 3]\n",
    "        df_mag['beta'] = imu_data_array[:, 4]\n",
    "        df_mag['gama'] = imu_data_array[:, 5]\n",
    "        return df_mag\n",
    "\n",
    "    def get_T_index(self, noise_threshould):\n",
    "        df_mag_merge = self.merge_all()\n",
    "        mag_array = np.array(df_mag_merge['Magnitude'].tolist())\n",
    "        mag_index = []\n",
    "        for rows in range(10, df_mag_merge.shape[0] - 100):\n",
    "            if np.sum(mag_array[rows - 1:rows + 4]) < np.sum(mag_array[rows:rows + 5]) and np.sum(\n",
    "                    mag_array[rows + 1:rows + 6]) < np.sum(mag_array[rows:rows + 5]) and np.min(\n",
    "                mag_array[rows:rows + 5]) > noise_threshould:  #### outdoor: 6800000\n",
    "                mag_index.append(rows)\n",
    "        T1_start = []\n",
    "        T2_start = []\n",
    "        T3_start = []\n",
    "\n",
    "        for index in range(len(mag_index) - 3):\n",
    "            if 7 < mag_index[index + 2] - mag_index[index + 1] < 11 and 7 < mag_index[index + 1] - mag_index[\n",
    "                index] < 11:\n",
    "                T1_start.append(mag_index[index])\n",
    "\n",
    "\n",
    "            elif 10 < mag_index[index + 2] - mag_index[index + 1] < 14 and 7 < mag_index[index + 1] - mag_index[\n",
    "                index] < 11:\n",
    "                T2_start.append(mag_index[index])\n",
    "\n",
    "            elif 7 < mag_index[index + 2] - mag_index[index + 1] < 11 and 10 < mag_index[index + 1] - mag_index[\n",
    "                index] < 14:\n",
    "                T3_start.append(mag_index[index])\n",
    "\n",
    "        return T1_start, T2_start, T3_start\n",
    "\n",
    "    def get_ml_features(self):\n",
    "        df_mag_merge = self.merge_all()\n",
    "        t1,t2,t3 = self.get_T_index(8000000)\n",
    "        period_start = []\n",
    "        for item in t1:\n",
    "            period_start.append(item)\n",
    "        for item in t2:\n",
    "            period_start.append(item - 40)\n",
    "        for item in t3:\n",
    "            period_start.append(item - 80)\n",
    "        T1_start = []\n",
    "        sorted_begin_list = sorted(period_start)\n",
    "        for i in range(1, len(period_start)):\n",
    "            if sorted_begin_list[i] - sorted_begin_list[i - 1] > 2:\n",
    "                T1_start.append(sorted_begin_list[i])\n",
    "        feature_list = []\n",
    "        feature_index = []\n",
    "        for item in T1_start:\n",
    "            feature_list.append(\n",
    "                (item, item + 9, item + 18, item + 40, item + 49, item + 60, item + 80, item + 92, item + 102))\n",
    "            feature_index.extend(\n",
    "                (item, item + 9, item + 18, item + 40, item + 49, item + 60, item + 80, item + 92, item + 102))\n",
    "        x_feature = []\n",
    "        y_feature = []\n",
    "\n",
    "        for item in feature_list:\n",
    "            x_feature.append([\n",
    "                max(df_mag_merge.iloc[item[0]:item[0] + 5, 4]),\n",
    "                max(df_mag_merge.iloc[item[1]:item[1] + 5, 4]),\n",
    "                max(df_mag_merge.iloc[item[2]:item[2] + 5, 4]),\n",
    "                max(df_mag_merge.iloc[item[3]:item[3] + 5, 4]),\n",
    "                max(df_mag_merge.iloc[item[4]:item[4] + 5, 4]),\n",
    "                max(df_mag_merge.iloc[item[5]:item[5] + 5, 4]),\n",
    "                max(df_mag_merge.iloc[item[6]:item[6] + 5, 4]),\n",
    "                max(df_mag_merge.iloc[item[7]:item[7] + 5, 4]),\n",
    "                max(df_mag_merge.iloc[item[8]:item[8] + 5, 4]),\n",
    "\n",
    "            ])\n",
    "            y_feature.append(\n",
    "                [df_mag_merge.iloc[item[0], 5], df_mag_merge.iloc[item[0], 6], df_mag_merge.iloc[item[0], 7]])\n",
    "        return x_feature,y_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Users/guoqiushi/Documents/thesis/indoor_final/'\n",
    "file_1  = ml_fileObject(root,1)\n",
    "file_2  = ml_fileObject(root,2)\n",
    "file_3  = ml_fileObject(root,3)\n",
    "file_4  = ml_fileObject(root,4)\n",
    "file_5  = ml_fileObject(root,5)\n",
    "file_6  = ml_fileObject(root,6)\n",
    "file_7  = ml_fileObject(root,7)\n",
    "file_8  = ml_fileObject(root,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feature_1,y_feature_1 = file_1.get_ml_features()\n",
    "x_feature_2,y_feature_2 = file_2.get_ml_features()\n",
    "x_feature_3,y_feature_3 = file_3.get_ml_features()\n",
    "x_feature_4,y_feature_4 = file_4.get_ml_features()\n",
    "x_feature_5,y_feature_5 = file_5.get_ml_features()\n",
    "x_feature_6,y_feature_6 = file_6.get_ml_features()\n",
    "x_feature_7,y_feature_7 = file_7.get_ml_features()\n",
    "x_feature_8,y_feature_8 = file_8.get_ml_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_feature_1+x_feature_2+x_feature_3+x_feature_4+x_feature_6+x_feature_7+x_feature_8\n",
    "y_train = y_feature_1+y_feature_2+y_feature_3+y_feature_4+y_feature_6+y_feature_7+y_feature_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "           n_jobs=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100,\n",
    "                                                          max_depth=20,\n",
    "                                                          random_state=0))\n",
    "rf_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = MultiOutputRegressor()\n",
    "svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9353858.29870252,\n",
       " 9467168.99101632,\n",
       " 9262116.353513759,\n",
       " 9310346.670313947,\n",
       " 8916899.226349203,\n",
       " 8600868.80754177,\n",
       " 14213933.59522708,\n",
       " 13768580.41947052,\n",
       " 10949723.31646791]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_feature_5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.82299337, -2.52721963,  0.92658378]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.predict([x_feature_5[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.7310000000000003, -2.573, 0.936]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_feature_5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
